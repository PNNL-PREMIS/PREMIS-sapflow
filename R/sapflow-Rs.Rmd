---
title: "sapflow-Rs"
author: "SP"
date: "9/10/2019"
output:
  html_document: default
---

**Title:** (From AGU) Using continuous sap flux and soil respiration datasets to infer the strength and speed of root-soil coupling in a deciduous forest

**Authors:** Stephanie C. Pennington, Ben Bond-Lamberty, Charlotte Grossiord, Wenzhi Wang, Nate McDowell

**Target Journal:**

**Overall Scientific Question:** What is strength and speed of above-belowground coupling (Js to Rs)?

### Data Prep and Preliminary Figures: 

```{r functions, include = FALSE, message = FALSE}
# Load functions
library(readr)
library(tidyr)
library(dplyr)
library(ggplot2)
theme_set(theme_minimal())
library(lubridate)
library(viridis)
library(wesanderson)
library(kableExtra)
library(suncalc)

# find matches
source(file = "find_day.R")

# count observations
log_obs <- function(d, step_name) {
  d %>% 
    ungroup() %>% 
    group_by(Tree) %>% 
    summarise(n = n()) %>% 
    mutate(step = step_name) %>% 
    bind_rows(obs_count_data) ->> obs_count_data
}

# compute rs-js correlation
compute_lag_cor <- function(rs, js, hour_range) {
  # `rs` and `js` are numeric vectors with the same length
  # hour_range is a numeric vector of length 2 that contains the start and end hour to lag
  hours <- min(hour_range):max(hour_range)
  result <- tibble(Hour = hours, Cor = NA)
  
  for(i in seq_along(hours)) {
    js_lag <- lead(js, n = hours[i])
    result$Cor[i] <- cor(rs, js_lag, use = "na.or.complete")
  }
  return(result)
}

```

```{r load-data, echo = FALSE, message = FALSE, warning = FALSE}
# Load in Rs, K, weather, and inventory data
inventory <- read_csv("../../PREMIS-stormsurge/inventory/ss-inventory.csv")
ports_lt <- read_csv("../../PREMIS-ghg/design/LT_portcodes.csv")
species_codes <- read_csv("../../PREMIS-ghg/inventory_data/species_codes.csv")

read_csv("../SERC/baseliner_data/control_Kest_yr.csv", 
         col_names = c("Year", "DOY","Time","VPD", "PAR", "C1", "C2", "C3", "C4", "C5", "C6", "C7", "C8")) %>% 
  mutate(Date = as_date(DOY - 1, origin = "2018-01-01")) %>% 
  separate(Date, c("Y", "Month", "Day"), sep = "-") %>% 
  separate(Time, c("Hour", "Min"), sep = -2) -> control_hm

control_hm$Hour[control_hm$Hour == ""] <- 0

control_hm %>% 
  mutate(Timestamp = mdy_hm(paste0(Month, "-", Day, "-", Year, " ", Hour, ":", Min), tz = "EST")) %>%
  select(-Y, -Year, - Day, - Month) %>% 
  gather("Tree", "K", C1:C8) %>% 
  left_join(inventory, by = c("Tree" = "Sapflux")) %>% 
  select(Timestamp, VPD, PAR, K, Tree, Species_code, Plot) -> control_long

##check where licor data is coming from 
read_csv("../SERC/con_licor_data_20191120.csv") %>%
  mutate(Timestamp = force_tz(Timestamp, tz = "EST")) %>% 
  left_join(ports_lt, by = "Port") %>% 
  left_join(inventory, by = c("Tree" = "Sapflux"))-> rs_long

# Load weather data
read_csv("../SERC/met_data/SECPRE_30min.csv") %>% 
  mutate(Timestamp = ymd_hms(endDateTime, tz = "UTC")) %>% 
  rename(Precip = secPrecipBulk) %>% 
  select(Timestamp, Precip) -> precip

read_csv("../SERC/met_data/RH_30min.csv") %>% 
  filter(horizontalPosition == "000", verticalPosition == "060") %>% 
  mutate(Timestamp = ymd_hms(endDateTime, tz = "UTC")) %>% 
  rename(RH = RHMean, Tair = tempRHMean) %>% 
  select(Timestamp, RH, Tair) -> temprh

read_csv("../SERC/met_data/PARPAR_30min.csv") %>% 
  filter(verticalPosition == "050") %>% 
  mutate(Timestamp = ymd_hms(endDateTime, tz = "UTC")) %>% 
  select(Timestamp, PAR = PARMean) %>%
  left_join(precip, by = "Timestamp") %>% 
  left_join(temprh, by = "Timestamp") %>% 
  # At this point convert everything to EST for the rest of the analysis
  # Note this doesn't change the times themselves, just associated time zone
  mutate(Timestamp = with_tz(Timestamp, tzone = "EST"),
         Timestamp = round_date(Timestamp, unit = "hour")) %>% 
  group_by(Timestamp) %>% 
  summarise(PAR = mean(PAR), 
            Precip = mean(Precip), 
            RH = mean(RH),
            Tair = mean(Tair)) %>% 
  mutate(DOY = yday(Timestamp), 
         Date = date(Timestamp)) -> wx_dat_no_dpar

# Compute daytime PAR as a new column
sunlight_times <- getSunlightTimes(wx_dat_no_dpar$Date,
                                   lat = 38.9, lon = -77, tz = "EST", 
                                   keep = c("sunrise", "sunset"))
wx_dat_no_dpar$sunrise <- sunlight_times$sunrise
wx_dat_no_dpar$sunset <- sunlight_times$sunset

wx_dat_no_dpar %>% 
  filter(Timestamp >= sunrise, Timestamp <= sunset) %>%   # daytime only
  group_by(DOY) %>% 
  summarise(Daytime_PAR = mean(PAR, na.rm = TRUE)) %>% 
  # we've computed mean *daytime* PAR; now merge back in
  right_join(wx_dat_no_dpar, by = "DOY") %>% 
  # compute daytime PAR groups - cloudy, medium, sunny
  group_by(month(Timestamp)) %>% 
  mutate(PAR_group = as.factor(ntile(Daytime_PAR, 3))) %>% 
  ungroup() %>% 
  select(-`month(Timestamp)`) ->  # no longer needed
  wx_dat
```

## Diagnostic plots for weather data

```{r, weather-qaqc}
# Monthly averages by hour for each variable
wx_dat %>% 
  gather(var, value, PAR, Precip, RH, Tair) %>% 
  mutate(month = month(Timestamp),
         hour = hour(Timestamp)) %>% 
  group_by(month, hour, var) %>% 
  summarise(value = mean(value, na.rm = TRUE)) %>%
  ggplot(aes(hour, value, color = month, group = month)) + 
  geom_line() + facet_grid(var~., scales = "free")

# Data by month for each variable, colored by day/night
wx_dat %>% 
  gather(var, value, PAR, Precip, RH, Tair) %>% 
  mutate(daytime = Timestamp >= sunrise & Timestamp <= sunset,
         month = month(Timestamp),
         hour = hour(Timestamp)) %>% 
  group_by(month, daytime, hour, var) %>% 
  summarise(value = mean(value, na.rm = TRUE)) %>%
  ggplot(aes(month, value, color = daytime, group = month)) + 
  geom_jitter() + facet_grid(var~., scales = "free")

# PAR versus PAR groups
ggplot(wx_dat, aes(DOY, PAR)) + 
  geom_point(alpha = 0.2) + 
  geom_point(aes(y = Daytime_PAR, color = PAR_group))
```


```{r data-cleaning, echo = FALSE, message = FALSE}
# Next, we need to filter for the Js trees that also have Rs measurements
rs_trees <- unique(ports_lt$Tree)
sunrise <- 6
sunset <- 19

control_long %>% 
  #Then, we need to transform K to Js (sapflux density) through a conversion
  mutate(Js = 119* 10^(-6) * K^(1.231)) %>% 
  filter(Tree %in% rs_trees) %>% 
  # Then, we need to round the timestamp to the nearest hour and take hourly averages
  mutate(Timestamp = round_date(Timestamp, unit = "hour")) %>% 
  # Now that all data are on a common timeframe, we can take the hourly mean of each dataset
  group_by(Timestamp, Tree, Species_code) %>% 
  summarise(Js_avg = mean(Js, na.rm = TRUE), 
            VPD_avg = mean(VPD, na.rm = TRUE)) -> control_filter

####RESOLVE THIS 
rs_long %>%
  mutate(Timestamp = round_date(Timestamp, unit = "hour")) %>%
  group_by(Timestamp, Tree, Species_code) %>%
  summarise(rs_avg = mean(Flux), 
            T5 = mean(T5, na.rm = TRUE), 
            SM = mean(SMoist, na.rm = TRUE)) %>% 
  # need to replace bad T5 and SM data - column flagging data 
  filter(rs_avg > 0, rs_avg < 25, SM > 0, SM < 1, T5 < 50) %>%
  ungroup() -> rs_filter

rs_long %>%
  filter(Flux > 0, Flux < 25, SMoist > 0) %>%
  mutate(Timestamp = round_date(Timestamp, unit = "hour")) %>%
  group_by(Timestamp, Tree, Species_code) %>%
  summarise(rs_avg = mean(Flux), 
            T5 = mean(T5), 
            SM = mean(SMoist)) %>% 
  ungroup() -> rs_filter

control_filter %>% 
  left_join(rs_filter) %>% 
  na.omit() %>% 
  left_join(wx_dat, by = "Timestamp") %>% 
  ungroup() %>% 
  complete(Tree, Timestamp = seq(ymd_hms(min(Timestamp)), ymd_hms(max(Timestamp)), by = "hour")) -> combined

# At this point, `combined` holds rs, js, and weather data rounded to the nearest hour

combined %>% 
  mutate(Hour = hour(Timestamp)) %>% 
  group_by(Timestamp, PAR_group, Tree, Species_code) %>% 
  summarise_if(is.numeric, mean, na.rm = TRUE) %>% 
  ungroup() %>% 
  mutate(Daytime = Hour > sunrise & Hour < sunset) %>% 
  left_join(species_codes) -> hourly
#add SM and temp
gather(hourly, key = "Type", value = "Value", rs_avg, Js_avg) -> hourly_long

combined %>% 
  mutate(Date = date(Timestamp)) %>% 
  group_by(Date, Tree, PAR_group) %>% 
  summarise_if(is.numeric, mean, na.rm = TRUE) %>% 
  ungroup() %>% 
  complete(Tree, Date = seq(ymd(min(Date)), ymd(max(Date)), by = "day")) -> daily
```

```{r check-count, echo = FALSE}
# Check Rs counts
obs_count_data <- tibble()
log_obs(rs_long, "1")
log_obs(rs_filter, "2")
log_obs(combined, "3")

ggplot(obs_count_data, aes(x = step, y = n, colour = Tree, group = Tree)) + 
  geom_line() -> rs_counts

# Check Js counts
tree_names <- c("C3", "C6", "C7", "C8")

obs_count_data <- tibble()
log_obs(control_long, "1")
log_obs(control_filter, "2")
log_obs(combined, "3")

obs_count_data %>% 
  filter(Tree %in% tree_names) %>% 
  ggplot(aes(x = step, y = n, color = Tree, group = Tree)) + 
  geom_line() -> js_counts
```

```{r hourly, echo = FALSE, message = FALSE}
rs_min <- 7
rs_max <- 11

hourly_long[which(hourly_long$Type == "Js_avg"), ] -> x

hourly_long %>% 
  ungroup %>% 
  filter(Type == "Js_avg") %>% 
  select(-Value) %>% 
  mutate(Value  = (rs_max - rs_min) * ((x$Value - min(x$Value)) / (max(x$Value) - min(x$Value))) + rs_min) -> hourly_check

hourly_long %>% 
  filter(Type == "rs_avg") %>% 
  bind_rows(hourly_check) -> hourly_norm

ggplot(filter(hourly_norm), aes(x = Hour, y = Value, color = Type, group = Type)) +
  geom_line() +
  geom_point(size = 1) +
  scale_color_viridis(discrete = TRUE, 
                      option = "D", 
                      begin =0.7, 
                      end = 0.4,
                      labels = c("Js", "Rs")) +
  labs(x = "Hour of Day", y = "Value") +
  facet_wrap(~Species) + 
  theme(strip.text.x = element_text(face = "bold.italic", size = 12)) 

```

```{r rs-js plot, echo = FALSE, message = FALSE}
ggplot(hourly, aes(x = Js_avg, rs_avg)) +
  geom_point(aes(color = Daytime)) +
  geom_smooth(aes(group = Daytime, color = Daytime, fill = Daytime), method = "lm") +
  scale_color_viridis(discrete = TRUE,
                      name = "Time of Day",
                      labels = c("Nighttime", "Daytime")) +
  scale_fill_viridis(discrete = TRUE,
                     name = "Time of Day",
                     labels = c("Nighttime", "Daytime")) +
  labs(x = "Js (m/s)", y = "Rs (umol/m/s)")

```

```{r Q10, echo = FALSE, message = FALSE}
# combined %>% 
#   mutate(Daytime = if_else(hour(Timestamp) > sunrise & hour(Timestamp) < sunset, TRUE, FALSE)) -> data
# 
# ## Daytime Q10
# daytime <- filter(data, Daytime == TRUE)
# model_d <- lm(log(rs_avg) ~ T5, data = daytime)
# daytime$prediction <- exp(predict(model_d))
# # ggplot(daytime, aes(x = T5, y = rs_avg)) + 
# #   geom_point() +
# #   geom_line(data = daytime, aes(y = prediction), linetype = 2)
# # cat("Model Q10 =", exp(10 ^ model_d$coefficients[2]))
# 
# ## Nighttime Q10
# nighttime <- filter(data, Daytime == FALSE)
# model_n <- lm(log(rs_avg) ~ T5, data = nighttime)
# nighttime$prediction <- exp(predict(model_n))
# ggplot(nighttime, aes(x = T5, y = rs_avg)) + 
#   geom_point() + 
#   geom_line(data = nighttime, aes(y = prediction), linetype = 2)
# cat("Model Q10 =", exp(10 ^ model_n$coefficients[2]))

## Plot
#ggplot(data, aes(x = T5, y = rs_avg, color = Daytime)) + 
# geom_point() +
# scale_color_viridis(discrete = TRUE,
#                     name = "Time of Day",
#                     labels = c("Nighttime", "Daytime")) +
# annotate("text", x = 10, y = 21.5, 
#          label = paste("Q10 =", round(exp(10 ^ model_d$coefficients[2]), digits = 3)), 
#          color = "#FDE725FF") +
# annotate("text", x = 10, y = 20, 
#         label = paste("Q10=", round(exp(10 ^ model_n$coefficients[2]), digits = 3)), 
#         color = "#440154FF") +
# theme_minimal()

```

```{r q0a, echo = FALSE}

ggplot(data = control_long, aes(x = Timestamp, y = K)) + 
  geom_line() + 
  facet_wrap(~Tree, scales = "free", ncol = 2)

ggplot(data = rs_long, aes(x = Timestamp, y = Flux)) +
  geom_line() +
  facet_wrap(~Tree, scales = "free")

```

```{r q0b, echo = FALSE}
# PACF temporal characteristics 

pacf(combined$rs_avg, na.action = na.pass)
pacf(combined$Js_avg, na.action = na.pass)

```

## Science Questions.
# {.tabset .tabset-pills}

### Q1: For the overall dataset, how correlated are Js and Rs, at what time lags? 
(Between the fluxes; here and afterward, on a per-tree basis.)

- Whole dataset
- Compute lag correlation for each tree - each timestamp hour

#### H1.1. Hypothesis-time. 
Js and Rs will be correlated at some lag of (probably) multiple hours, because of the time it takes for sap to ascend; photosynthesis to occur; phloem to descend to roots; respiration to occur; and resulting CO2 to diffuse to soil surface .

#### H1.2 Hypothesis-species. 
We expect there to be differences in peak lag and correlation between the two species - Tulip Poplar and Red Maple - driven by path length difference and light availability.

```{r q1, echo = FALSE}

combined %>%
  group_by(Tree) %>%
  do(compute_lag_cor(.$rs_avg, .$Js_avg, hour_range = c(0, 23))) -> q1

ggplot(q1, aes(x = Hour, y = Cor, color = Tree)) + geom_line()

q1 %>% 
  left_join(inventory, by = c("Tree" = "Sapflux")) %>% 
  select(Tree, Species_code, Hour, Cor) %>% 
  group_by(Tree) %>% 
  summarise(`Species` = Species_code[which.max(Cor)], 
            `Hour Lag` = Hour[which.max(Cor)], 
            `Maximum Correlation` = max(Cor)) %>% 
  kable("html") %>% 
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

```

### Q2: How does this change over the course of the growing season? 

- For each day (week?) of year, calculate the correlation between Js and Rs for each hour lag (using function) and pull out max correlation lag
- Dendrometer data to show growth changes?

#### H2.1. Hypothesis. 
We expect to see changes in the strength and speed of coupling, probably because of seasonal changes in photosynthetic capacity and carbon allocation (e.g. reflected in stem diameter growth data).

```{r q2, echo = FALSE}
growing_season <- c(5, 6, 7, 8, 9, 10)

combined %>% 
  mutate(Month = month(Timestamp), Week = week(Timestamp)) %>% 
  filter(Month %in% growing_season) -> growing # filter for growing season

weeks <- sort(unique(growing$Week))
q2_list <- list() 

for(i in 1:length(weeks)) {
  
  growing %>% 
    filter(Week == weeks[i]) %>% 
    group_by(Tree) %>% 
    do(compute_lag_cor(.$rs_avg, .$Js_avg, hour_range = c(0,23))) -> tib 
  
  q2_list[[as.character(weeks[i])]] <- tib
  
}

bind_rows(q2_list, .id = "Week") %>% na.omit() -> q2

ggplot(data = q2, aes(x = as.numeric(Week), y = Hour, fill = Cor)) + 
  geom_tile() + 
  facet_wrap(~Tree) + 
  geom_vline(xintercept = 30) +
  scale_fill_distiller(palette = "RdBu")

```

### Q3: Is this correlation or causation? 

#### H3.1. Hypothesis. 
If H1.1 is correct, then days with more sunlight would have a stronger correlation.

To examine this issue, we look at matched days, i.e. that are in the same part of the growing season and have similar conditions EXCEPT for sunlight.

**Goal:** To compare Rs:Js correlation of sunny vs. cloudy days. We essentially are testing the important of PAR on the relationship.

- Rs, Js, and climate variables parsed to same timescale
- Data separated into **sunny days** (top 1/3 PAR) and **cloudy days** (bottom 1/3 PAR)
- Just the matched days, how do the max-cor-lags differ between them?
- Tree, DOY, Match_doy, Max_Cor, Lag_max_cor, Coverage

```{r sc-setup, echo=FALSE, message=FALSE, warning=FALSE}

# Take full dataset and split into groups based on PAR
daily %>% 
  filter(!is.na(PAR_group)) %>% 
  mutate(Coverage = c("Cloudy", "Medium", "Sunny")[PAR_group]) -> full_sc

sunny_days <- filter(full_sc, Coverage == "Sunny") %>% pull(DOY) %>% unique()
cloudy_days <- filter(full_sc, Coverage == "Cloudy") %>% pull(DOY) %>% unique()

full_sc %>% 
  select(DOY, VPD = VPD_avg, T5, SM, Precip, RH, Tair) %>% 
  group_by(DOY) %>% 
  summarise_all(mean, na.rm = TRUE) ->
  climate_data

# fsd - find similar days for sunny_days (numeric vector)
fsd <- function(sunny_days, climate_data, lookahead, constraints) {
  matches <- list()
  for(sd in sunny_days) {
    matches[[sd]] <- tibble(DOY = sd,
                            Similar_Day = similar_days(sd, climate_data, lookahead, constraints))
  }
  bind_rows(matches)
}
```

## Similar_days sensitivty analysis

```{r sc-sensitivity, echo=FALSE}
constraints <- c("VPD" = 1, "T5" = 5, "SM" = 1, "RH" = 30, "Tair" = 15)

daycount <- function(constraints, lookahead = 20) {
  suppressMessages(
    nrow(fsd(sunny_days, climate_data, lookahead, constraints))
  )
}

la_seq <- 1:20
df1 <- tibble(variable = "lookahead",
              value = la_seq,
              daycount = sapply(la_seq, function(x) daycount(constraints, lookahead = x)))
vpd_seq <- seq(0.01, 1, length.out = 20)
df2 <- tibble(variable = "vpd",
              value = vpd_seq,
              daycount = sapply(vpd_seq, function(x) daycount(constraints = c("VPD" = x))))
t5_seq <- seq(0.1, 5, length.out = 20)
df3 <- tibble(variable = "T5",
              value = t5_seq,
              daycount = sapply(vpd_seq, function(x) daycount(constraints = c("T5" = x))))
tair_seq <- seq(0.1, 5, length.out = 20)
df4 <- tibble(variable = "Tair",
              value = tair_seq,
              daycount = sapply(vpd_seq, function(x) daycount(constraints = c("Tair" = x))))
sm_seq <- seq(0.05, 1, length.out = 20)
df5 <- tibble(variable = "SM",
              value = sm_seq,
              daycount = sapply(sm_seq, function(x) daycount(constraints = c("SM" = x))))
rh_seq <- seq(5, 50, length.out = 20)
df6 <- tibble(variable = "RH",
              value = rh_seq,
              daycount = sapply(sm_seq, function(x) daycount(constraints = c("RH" = x))))

bind_rows(df1, df2, df3, df4, df5, df6) %>% 
  ggplot(aes(value, daycount)) + 
  geom_line() +
  xlab("Constraint value") + ylab("Number of matched days") +
  facet_wrap(~variable, scales = "free")
```



```{r sc-compute, echo=FALSE, message=FALSE, warning=FALSE}
fsd(sunny_days, climate_data, lookahead = 14, constraints) %>% 
  filter(Similar_Day %in% cloudy_days) %>% 
  rename(Sunny_DOY = DOY, Cloudy_DOY = Similar_Day) -> matched_DOY

left_join(matched_DOY, combined, by = c("Cloudy_DOY" = "DOY")) %>%
  mutate(Coverage = "Cloudy") %>% 
  rename(DOY = Cloudy_DOY, Group_No = Sunny_DOY) -> cloudy_complete

left_join(matched_DOY, combined, by = c("Sunny_DOY" = "DOY")) %>% 
  mutate(Coverage = "Sunny", Group_No = Sunny_DOY) %>% 
  rename(DOY = Sunny_DOY) %>% 
  select(-Cloudy_DOY) -> sunny_complete

bind_rows(cloudy_complete, sunny_complete) -> matches_data
```


```{r q3a, echo = FALSE}
# Lag over whole growing season by sunny vs. cloudy
# should be using DAILY PAR FOR THIS!!!!!!!!!!!!
full_sc %>%
  group_by(Tree, Coverage) %>% na.omit() %>% 
  do(compute_lag_cor(.$rs_avg, .$Js_avg, hour_range = c(0, 23))) -> q3a

ggplot(data = q3a, aes(x = Hour, y = Cor, color = Coverage, group = Coverage)) + 
  geom_line() +
  facet_wrap(~Tree)

```

```{r q3b, echo = FALSE, message = FALSE}
# Plot of sunny DOYs with cloudy DOYs

# ggplot(matches_data, aes(x = hour(Timestamp), y = Js_avg, color = Coverage, group = DOY)) + 
#   geom_point() + geom_line() +  
#   facet_wrap(Tree~Group_No, scales = "free") + theme_minimal()
# 
# ggplot(matches_data, aes(x = hour(Timestamp), y = rs_avg, color = Coverage, group = DOY)) + 
#   geom_point() + geom_line() + 
#   facet_wrap(Tree~Group_No, scales = "free") + theme_minimal()
```

```{r q10-sunny-cloudy, echo = FALSE, message = FALSE}

## Sunny Q10
sunny <- filter(matches_data, Coverage == "Sunny", !is.na(T5), !is.na(rs_avg))
model_s <- lm(log(rs_avg) ~ T5, data = sunny)
sunny$prediction <- exp(predict(model_s))
# ggplot(daytime, aes(x = T5, y = rs_avg)) + 
#   geom_point() +
#   geom_line(data = daytime, aes(y = prediction), linetype = 2)
# cat("Model Q10 =", exp(10 ^ model_d$coefficients[2]))

## Cloudy Q10
cloudy <- filter(matches_data, Coverage == "Cloudy", !is.na(T5), !is.na(rs_avg))
model_c <- lm(log(rs_avg) ~ T5, data = cloudy)
cloudy$prediction <- exp(predict(model_c))
# ggplot(nighttime, aes(x = T5, y = rs_avg)) + 
#   geom_point() + 
#   geom_line(data = nighttime, aes(y = prediction), linetype = 2)
# cat("Model Q10 =", exp(10 ^ model_n$coefficients[2]))

## Plot
ggplot(matches_data, aes(x = T5, y = rs_avg, color = Coverage)) + 
  geom_point() +
  scale_color_viridis(discrete = TRUE) +
  annotate("text", x = 10, y = 21.5, 
           label = paste("Q10 =", round(exp(10 ^ model_s$coefficients[2]), digits = 3)), 
           color = "#FDE725FF") +
  annotate("text", x = 10, y = 20, 
           label = paste("Q10=", round(exp(10 ^ model_c$coefficients[2]), digits = 3)), 
           color = "#440154FF")

```

