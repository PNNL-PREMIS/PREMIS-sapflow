---
title: "sapflow-Rs"
author: "SP"
date: "9/10/2019"
output:
  html_document: default
---

**Title:** (From AGU) Using continuous sap flux and soil respiration datasets to infer the strength and speed of root-soil coupling in a deciduous forest

**Authors:** Stephanie C. Pennington, Ben Bond-Lamberty, Charlotte Grossiord, Wenzhi Wang, Nate McDowell

**Target Journal:**

**Overall Scientific Question:** What is strength and speed of above-belowground coupling (Js to Rs)?

### Data Prep and Preliminary Figures: 

```{r functions, include = FALSE, message = FALSE}
# Load functions
library(readr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(lubridate)
library(viridis)
library(wesanderson)
library(kableExtra)
library(suncalc)

# find matches
source(file = "find_day.R")

# count observations
log_obs <- function(d, step_name) {
  d %>% 
    ungroup() %>% 
    group_by(Tree) %>% 
    summarise(n = n()) %>% 
    mutate(step = step_name) %>% 
    bind_rows(obs_count_data) ->> obs_count_data
}

# compute rs-js correlation
compute_lag_cor <- function(rs, js, hour_range) {
  # `rs` and `js` are numeric vectors with the same length
  # hour_range is a numeric vector of length 2 that contains the start and end hour to lag
  hours <- min(hour_range):max(hour_range)
  result <- tibble(Hour = hours, Cor = NA)
  
  for(i in seq_along(hours)) {
    js_lag <- lead(js, n = hours[i])
    result$Cor[i] <- cor(rs, js_lag, use = "na.or.complete")
  }
  return(result)
}

```

```{r load-data, echo = FALSE, message = FALSE, warning = FALSE}
# Load in Rs, K, weather, and inventory data
inventory <- read_csv("../../PREMIS-stormsurge/inventory/ss-inventory.csv")
ports_lt <- read_csv("../../PREMIS-ghg/design/LT_portcodes.csv")
species_codes <- read_csv("../../PREMIS-ghg/inventory_data/species_codes.csv")

read_csv("../SERC/baseliner_data/control_Kest_yr.csv", 
         col_names = c("Year", "DOY","Time","VPD", "PAR", "C1", "C2", "C3", "C4", "C5", "C6", "C7", "C8")) %>% 
  mutate(Date = as_date(DOY - 1, origin = "2018-01-01")) %>% 
  separate(Date, c("Y", "Month", "Day"), sep = "-") %>% 
  separate(Time, c("Hour", "Min"), sep = -2) -> control_hm
  
control_hm$Hour[control_hm$Hour == ""] <- 0

control_hm %>% 
  mutate(Timestamp = mdy_hm(paste0(Month, "-", Day, "-", Year, " ", Hour, ":", Min), tz = "EST")) %>%
  select(-Y, -Year, - Day, - Month) %>% 
  gather("Tree", "K", C1:C8) %>% 
  left_join(inventory, by = c("Tree" = "Sapflux")) %>% 
  select(Timestamp, VPD, PAR, K, Tree, Species_code, Plot) -> control_long

##check where licor data is coming from 
read_csv("../SERC/con_licor_data_20191120.csv") %>%
  mutate(Timestamp = force_tz(Timestamp, tz = "EST")) %>% 
  left_join(ports_lt, by = "Port") %>% 
  left_join(inventory, by = c("Tree" = "Sapflux"))-> rs_long

# Load weather data
read_csv("../SERC/met_data/SECPRE_30min.csv") %>% 
  mutate(Timestamp = ymd_hms(endDateTime, tz = "UTC")) %>% 
  rename(Precip = secPrecipBulk) %>% 
  select(Timestamp, Precip) -> precip

read_csv("../SERC/met_data/RH_30min.csv") %>% 
  filter(horizontalPosition == "000", verticalPosition == "060") %>% 
  mutate(Timestamp = ymd_hms(endDateTime, tz = "UTC")) %>% 
  rename(RH = RHMean, Tair = tempRHMean) %>% 
  select(Timestamp, RH, Tair) -> temprh

read_csv("../SERC/met_data/PARPAR_30min.csv") %>% 
  filter(verticalPosition == "050") %>% 
  mutate(Timestamp = ymd_hms(endDateTime, tz = "UTC")) %>% 
  select(Timestamp, PAR = PARMean) %>%
  left_join(precip, by = "Timestamp") %>% 
  left_join(temprh, by = "Timestamp") %>% 
  mutate(Timestamp = round_date(Timestamp, unit = "hour")) %>% 
  group_by(Timestamp) %>% 
  summarise(PAR = mean(PAR), 
            Precip = mean(Precip), 
            RH = mean(RH),
            Tair = mean(Tair)) %>% 
  mutate(DOY = yday(Timestamp), 
         Date = date(Timestamp)) -> wx_dat_no_dpar

# Compute daytime PAR as a new column
sunlight_times <- getSunlightTimes(wx_dat_no_dpar$Date,
                                   lat = 38.9, lon = -77, tz = "EST", 
                                   keep = c("sunrise", "sunset"))
wx_dat_no_dpar$sunrise <- sunlight_times$sunrise
wx_dat_no_dpar$sunset <- sunlight_times$sunset

wx_dat_no_dpar %>% 
  filter(Timestamp >= sunrise, Timestamp <= sunset) %>%   # daytime only
  group_by(DOY) %>% 
  summarise(Daytime_PAR = mean(PAR, na.rm = TRUE)) %>% 
  # we've computed mean *daytime* PAR; now merge back in
  right_join(wx_dat_no_dpar, by = "DOY") %>% 
  # compute daytime PAR groups - sunny, medium, cloudy
  group_by(month(Timestamp)) %>% 
  mutate(PAR_group = ntile(Daytime_PAR, 3)) %>% 
  ungroup() %>% 
  select(-`month(Timestamp)`) ->  # no longer needed
  wx_dat
```

TODO: diagnostic plots for weather data
```{r, weather-qaqc}
ggplot(wx_dat, aes(DOY, PAR)) + 
  geom_point(alpha = 0.2) + 
  geom_point(aes(y = Daytime_PAR, color = PAR_group))
```


```{r data-cleaning, echo = FALSE, message = FALSE}
# Next, we need to filter for the Js trees that also have Rs measurements
rs_trees <- unique(ports_lt$Tree)
sunrise <- 6
sunset <- 19

control_long %>% 
  #Then, we need to transform K to Js (sapflux density) through a conversion
  mutate(Js = 119* 10^(-6) * K^(1.231)) %>% 
  filter(Tree %in% rs_trees) %>% 
  # Then, we need to round the timestamp to the nearest hour and take hourly averages
  mutate(Timestamp = round_date(Timestamp, unit = "hour")) %>% 
  # Now that all data are on a common timeframe, we can take the hourly mean of each dataset
  group_by(Timestamp, Tree, Species_code) %>% 
  summarise(Js_avg = mean(Js, na.rm = TRUE), VPD_avg = mean(VPD, na.rm = TRUE)) -> control_filter

####RESOLVE THIS 
rs_long %>%
  mutate(Timestamp = round_date(Timestamp, unit = "hour")) %>%
  group_by(Timestamp, Tree, Species_code) %>%
  summarise(rs_avg = mean(Flux), T5 = mean(T5, na.rm = TRUE), SM = mean(SMoist, na.rm = TRUE)) %>% 
  # need to replace bad T5 and SM data - column flagging data 
  filter(rs_avg > 0, rs_avg < 25, SM > 0, SM < 1, T5 < 50) %>%
  ungroup() -> rs_filter

rs_long %>%
  filter(Flux > 0, Flux < 25, SMoist > 0) %>%
  mutate(Timestamp = round_date(Timestamp, unit = "hour")) %>%
  group_by(Timestamp, Tree, Species_code) %>%
  summarise(rs_avg = mean(Flux), T5 = mean(T5), SM = mean(SMoist)) %>% 
  ungroup() -> rs_filter

control_filter %>% 
  left_join(rs_filter) %>% 
  na.omit() %>% 
  left_join(wx_dat, by = "Timestamp") %>% 
  mutate(DOY = yday(Timestamp)) %>% 
  ungroup() %>% 
  complete(Tree, Timestamp = seq(ymd_hms(min(Timestamp)), ymd_hms(max(Timestamp)), by = "hour")) -> combined

# At this point, `combined` holds rs, js, and weather data rounded to the nearest hour

combined %>% 
  mutate(Hour = hour(Timestamp)) %>% 
  group_by(Hour, Species_code) %>% 
  summarise(rs_havg = mean(rs_avg, na.rm = TRUE), Js_havg = mean(Js_avg, na.rm = TRUE), 
            DOY = mean(DOY, na.rm = TRUE), PAR = mean(PAR, na.rm = TRUE), 
            Precip = mean(Precip, na.rm = TRUE), VPD = mean(VPD_avg, na.rm = TRUE),
            RH = mean(RH, na.rm = TRUE), Tair = mean(Tair, na.rm = TRUE),
            SM = mean(SM, na.rm = TRUE), Tsoil = mean(T5, na.rm = TRUE)) %>% 
  mutate(Daytime = if_else(Hour > sunrise & Hour < sunset, TRUE, FALSE)) %>% 
  left_join(species_codes) -> hourly
#add SM and temp
gather(hourly, key = "Type", value = "Value", rs_havg:Js_havg) -> hourly_long

combined %>% 
  mutate(Date = date(Timestamp)) %>% 
  group_by(Date, Tree) %>% 
  summarise(rs_daily = mean(rs_avg, na.rm = TRUE), Js_daily = mean(Js_avg, na.rm = TRUE), 
            DOY = mean(DOY, na.rm = TRUE), PAR = mean(PAR, na.rm = TRUE), 
            Precip = mean(Precip, na.rm = TRUE), VPD = mean(VPD_avg, na.rm = TRUE),
            RH = mean(RH, na.rm = TRUE), Tair = mean(Tair, na.rm = TRUE), 
            SM = mean(SM, na.rm = TRUE), T5 = mean(T5, na.rm = TRUE)) %>% 
  ungroup() %>% 
  complete(Tree, Date = seq(ymd(min(Date)), ymd(max(Date)), by = "day"))-> daily

```

```{r check-count, echo = FALSE}
# Check Rs counts
obs_count_data <- tibble()
log_obs(rs_long, "1")
log_obs(rs_filter, "2")
log_obs(combined, "3")

ggplot(obs_count_data, aes(x = step, y = n, colour = Tree, group = Tree)) + 
  geom_line() +
  theme_minimal() -> rs_counts

# Check Js counts
tree_names <- c("C3", "C6", "C7", "C8")

obs_count_data <- tibble()
log_obs(control_long, "1")
log_obs(control_filter, "2")
log_obs(combined, "3")

ggplot(filter(obs_count_data, Tree %in% tree_names), aes(x = step, y = n, color = Tree, group = Tree)) + 
  geom_line() +
  theme_minimal() -> js_counts

```

```{r hourly, echo = FALSE, message = FALSE}
rs_min <- 7
rs_max <- 11

hourly_long[which(hourly_long$Type == "Js_havg"), ] -> x

hourly_long %>% 
  ungroup %>% 
  filter(Type == "Js_havg") %>% 
  select(-Value) %>% 
  mutate(Value  = (rs_max - rs_min) * ((x$Value - min(x$Value))/(max(x$Value) - min(x$Value))) + rs_min) -> hourly_check

hourly_long %>% 
  filter(Type == "rs_havg") %>% 
  bind_rows(hourly_check) -> hourly_norm

ggplot(filter(hourly_norm), aes(x = Hour, y = Value, color = Type, group = Type)) +
  geom_line() +
  geom_point(size = 1) +
  scale_color_viridis(discrete = TRUE, 
                      option = "D", 
                      begin =0.7, 
                      end = 0.4,
                      labels = c("Js", "Rs")) +
  labs(x = "Hour of Day", y = "Value") +
  facet_wrap(~Species) + 
  theme_minimal() +
  theme(strip.text.x = element_text(face = "bold.italic", size = 12)) 
  
```

```{r rs-js plot, echo = FALSE, message = FALSE}
ggplot(hourly, aes(x = Js_havg, rs_havg)) +
  geom_point(aes(color = Daytime)) +
  geom_smooth(aes(group = Daytime, color = Daytime, fill = Daytime), method = "lm") +
  scale_color_viridis(discrete = TRUE,
                      name = "Time of Day",
                      labels = c("Nighttime", "Daytime")) +
  scale_fill_viridis(discrete = TRUE,
                     name = "Time of Day",
                     labels = c("Nighttime", "Daytime")) +
  labs(x = "Js (m/s)", y = "Rs (umol/m/s)") +
  theme_minimal()

```

```{r Q10, echo = FALSE, message = FALSE}
# combined %>% 
#   mutate(Daytime = if_else(hour(Timestamp) > sunrise & hour(Timestamp) < sunset, TRUE, FALSE)) -> data
# 
# ## Daytime Q10
# daytime <- filter(data, Daytime == TRUE)
# model_d <- lm(log(rs_avg) ~ T5, data = daytime)
# daytime$prediction <- exp(predict(model_d))
# # ggplot(daytime, aes(x = T5, y = rs_avg)) + 
# #   geom_point() +
# #   geom_line(data = daytime, aes(y = prediction), linetype = 2)
# # cat("Model Q10 =", exp(10 ^ model_d$coefficients[2]))
# 
# ## Nighttime Q10
# nighttime <- filter(data, Daytime == FALSE)
# model_n <- lm(log(rs_avg) ~ T5, data = nighttime)
# nighttime$prediction <- exp(predict(model_n))
# ggplot(nighttime, aes(x = T5, y = rs_avg)) + 
#   geom_point() + 
#   geom_line(data = nighttime, aes(y = prediction), linetype = 2)
# cat("Model Q10 =", exp(10 ^ model_n$coefficients[2]))

## Plot
#ggplot(data, aes(x = T5, y = rs_avg, color = Daytime)) + 
  # geom_point() +
  # scale_color_viridis(discrete = TRUE,
  #                     name = "Time of Day",
  #                     labels = c("Nighttime", "Daytime")) +
  # annotate("text", x = 10, y = 21.5, 
  #          label = paste("Q10 =", round(exp(10 ^ model_d$coefficients[2]), digits = 3)), 
  #          color = "#FDE725FF") +
  # annotate("text", x = 10, y = 20, 
  #         label = paste("Q10=", round(exp(10 ^ model_n$coefficients[2]), digits = 3)), 
  #         color = "#440154FF") +
  # theme_minimal()

```

```{r q0a, echo = FALSE}

ggplot(data = control_long, aes(x = Timestamp, y = K)) + 
  geom_line() + 
  facet_wrap(~Tree, scales = "free", ncol = 2) +
  theme_minimal()

ggplot(data = rs_long, aes(x = Timestamp, y = Flux)) +
  geom_line() +
  facet_wrap(~Tree, scales = "free") +
  theme_minimal()

```

```{r q0b, echo = FALSE}
# PACF temporal characteristics 

pacf(combined$rs_avg, na.action = na.pass)
pacf(combined$Js_avg, na.action = na.pass)

```

## Science Questions.
# {.tabset .tabset-pills}

### Q1: For the overall dataset, how correlated are Js and Rs, at what time lags? 
(Between the fluxes; here and afterward, on a per-tree basis.)

- Whole dataset
- Compute lag correlation for each tree - each timestamp hour

#### H1.1. Hypothesis-time. 
Js and Rs will be correlated at some lag of (probably) multiple hours, because of the time it takes for sap to ascend; photosynthesis to occur; phloem to descend to roots; respiration to occur; and resulting CO2 to diffuse to soil surface .

#### H1.2 Hypothesis-species. 
We expect there to be differences in peak lag and correlation between the two species - Tulip Poplar and Red Maple - driven by path length difference and light availability.

```{r q1, echo = FALSE}

full %>%
  group_by(Tree) %>%
  do(compute_lag_cor(.$rs_avg, .$Js_avg, hour_range = c(0,23))) -> q1

ggplot(q1, aes(x = Hour, y = Cor, color = Tree)) + geom_line() + theme_minimal()

q1 %>% 
  left_join(inventory, by = c("Tree" = "Sapflux")) %>% 
  select(Tree, Species_code, Hour, Cor) %>% 
  group_by(Tree) %>% 
  summarise(`Species` = Species_code[which.max(Cor)], `Hour Lag` = Hour[which.max(Cor)], `Maximum Correlation` = max(Cor)) %>% 
  kable("html") %>% kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

```

### Q2: How does this change over the course of the growing season? 

- For each day (week?) of year, calculate the correlation between Js and Rs for each hour lag (using function) and pull out max correlation lag
- Dendrometer data to show growth changes?

#### H2.1. Hypothesis. 
We expect to see changes in the strength and speed of coupling, probably because of seasonal changes in photosynthetic capacity and carbon allocation (e.g. reflected in stem diameter growth data).

```{r q2, echo = FALSE}
growing_season <- c(5, 6, 7, 8, 9, 10)

combined %>% 
  mutate(Month = month(Timestamp), Week = week(Timestamp)) %>% 
  filter(Month %in% growing_season) -> growing # filter for growing season

weeks <- sort(unique(growing$Week))
q2_list <- list() 

for(i in 1:length(weeks)) {
  
  growing %>% 
    filter(Week == weeks[i]) %>% 
    group_by(Tree) %>% 
    do(compute_lag_cor(.$rs_avg, .$Js_avg, hour_range = c(0,23))) -> tib 
  
  q2_list[[as.character(weeks[i])]] <- tib
  
}

bind_rows(q2_list, .id = "Week") %>% na.omit() -> q2

ggplot(data = q2, aes(x = as.numeric(Week), y = Hour, fill = Cor)) + 
  geom_tile() + 
  facet_wrap(~Tree) + 
  theme_minimal() + 
  geom_vline(xintercept = 30) +
  scale_fill_distiller(palette = "RdBu")

```

### Q3: Is this correlation or causation? 

#### H3.1. Hypothesis. 
If H1.1 is correct, then days with more sunlight would have a stronger correlation.

To examine this issue, we look at matched days, i.e. that are in the same part of the growing season and have similar conditions EXCEPT for sunlight.

**Goal:** To compare Rs:Js correlation of sunny vs. cloudy days. We essentially are tested the important of PAR on the relationship.

- Rs, Js, and climate variables parsed to same timescale
- Data separated into **sunny days** (top 1/3 PAR) and **cloudy days** (bottom 1/3 PAR)
- Just the matched days, how do the max-cor-lags differ between them?
- Tree, DOY, Match_doy, Max_Cor, Lag_max_cor, Coverage


```{r sunny-cloudy, echo=FALSE, message=FALSE, warning=FALSE, include=}

#Take full dataset and split into groups based on PAR
combined %>% 
  ungroup %>% 
  mutate(PAR_group = ntile(PAR, 3)) %>% 
  filter(PAR_group == "1" | PAR_group == "3") %>% 
  mutate(Coverage = ifelse(PAR_group == "3", "Sunny", "Cloudy")) -> full_sc

# Filter for sunlight and split into terciles 
daily %>%
  left_join(sunlight_times, by = c("Date" = "date")) %>% 
  filter() %>% # NEED TO FILTER OUT NIGHT
  mutate(group = ntile(PAR, 3)) -> PAR_groups #ntile should be using DAYTIME par values

pal <- (wes_palette(name = "Zissou1", 3, type = "continuous"))

ggplot(PAR_groups, aes(x = group, y = log(PAR), color = as.factor(group))) + 
  geom_jitter() + 
  ggtitle("PAR") + 
  scale_colour_manual(values = pal, name = "Tercile") + 
  theme_minimal()

sunny <- filter(PAR_groups, group == "3") %>% select(DOY)
cloudy <- filter(PAR_groups, group == "1") %>% select(DOY)

combined %>% 
  ungroup() %>% 
  select(DOY, VPD_avg, T5, SM, Precip, RH, Tair) %>% 
  group_by(DOY) %>% 
  summarise(VPD = mean(VPD_avg), T5 = mean(T5), SM = mean(SM),
            Precip = mean(Precip), RH = mean(RH, na.rm = T), Tair = mean(Tair, na.rm = T)) -> climate_data

constraints <- c("VPD" = 1, "T5" = 5, "SM" = 1, "Precip" = 4, "RH" = 30, "Tair" = 15)

matches <- list()

for(i in 1:nrow(daily)) {
  matches[[i]] <- tibble(DOY = daily$DOY[i], Similar_Day = similar_days(daily$DOY[i], climate_data, lookahead = 7, constraints))
}

bind_rows(matches) -> matches_df

matches_df %>% 
  filter(DOY %in% sunny$DOY) %>% 
  filter(Similar_Day %in% cloudy$DOY) %>% 
  rename(Sunny_DOY = DOY, Cloudy_DOY = Similar_Day) -> matched_DOY

left_join(matched_DOY, combined, by = c("Cloudy_DOY" = "DOY")) %>%
  mutate(Coverage = "Cloudy") %>% 
  rename(DOY = Cloudy_DOY, Group_No = Sunny_DOY) -> cloudy_complete

left_join(matched_DOY, combined, by = c("Sunny_DOY" = "DOY")) %>% 
  mutate(Coverage = "Sunny", Group_No = Sunny_DOY) %>% 
  rename(DOY = Sunny_DOY) %>% 
  select(-Cloudy_DOY) -> sunny_complete

bind_rows(cloudy_complete, sunny_complete) -> matches_data

```

```{r q3a, echo = FALSE}
# Lag over whole growing season by sunny vs. cloudy
# should be using DAILY PAR FOR THIS!!!!!!!!!!!!
full_sc %>%
  group_by(Tree, Coverage) %>% na.omit() %>% 
  do(compute_lag_cor(.$rs_avg, .$Js_avg, hour_range = c(0,23))) -> q3a

ggplot(data = q3a, aes(x = Hour, y = Cor, color = Coverage, group = Coverage)) + 
  geom_line() +
  facet_wrap(~Tree) +
  theme_minimal()

```

```{r q3b, echo = FALSE, message = FALSE}
# Plot of sunny DOYs with cloudy DOYs

# ggplot(matches_data, aes(x = hour(Timestamp), y = Js_avg, color = Coverage, group = DOY)) + 
#   geom_point() + geom_line() +  
#   facet_wrap(Tree~Group_No, scales = "free") + theme_minimal()
# 
# ggplot(matches_data, aes(x = hour(Timestamp), y = rs_avg, color = Coverage, group = DOY)) + 
#   geom_point() + geom_line() + 
#   facet_wrap(Tree~Group_No, scales = "free") + theme_minimal()
```

```{r q10-sunny-cloudy, echo = FALSE, message = FALSE}

## Sunny Q10
sunny <- filter(matches_data, Coverage == "Sunny")
model_s <- lm(log(rs_avg) ~ T5, data = sunny)
sunny$prediction <- exp(predict(model_s))
# ggplot(daytime, aes(x = T5, y = rs_avg)) + 
#   geom_point() +
#   geom_line(data = daytime, aes(y = prediction), linetype = 2)
# cat("Model Q10 =", exp(10 ^ model_d$coefficients[2]))

## Cloudy Q10
cloudy <- filter(matches_data, Coverage == "Cloudy")
model_c <- lm(log(rs_avg) ~ T5, data = cloudy)
cloudy$prediction <- exp(predict(model_c))
# ggplot(nighttime, aes(x = T5, y = rs_avg)) + 
#   geom_point() + 
#   geom_line(data = nighttime, aes(y = prediction), linetype = 2)
# cat("Model Q10 =", exp(10 ^ model_n$coefficients[2]))

## Plot
ggplot(matches_data, aes(x = T5, y = rs_avg, color = Coverage)) + 
  geom_point() +
  scale_color_viridis(discrete = TRUE) +
  annotate("text", x = 10, y = 21.5, 
           label = paste("Q10 =", round(exp(10 ^ model_s$coefficients[2]), digits = 3)), 
           color = "#FDE725FF") +
  annotate("text", x = 10, y = 20, 
          label = paste("Q10=", round(exp(10 ^ model_c$coefficients[2]), digits = 3)), 
          color = "#440154FF") +
  theme_minimal()

```

