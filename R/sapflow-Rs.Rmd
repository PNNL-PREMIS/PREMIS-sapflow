---
title: "sapflow-Rs"
author: "SP"
date: "9/10/2019"
output: html_document
---

**Title:** (From AGU) Using continuous sap flux and soil respiration datasets to infer the strength and speed of root-soil coupling in a deciduous forest

**Authors:** Stephanie C. Pennington, Ben Bond-Lamberty, Charlotte Grossiord, Wenzhi Wang, Nate McDowell

**Target Journal:**

**Primary Objective:** Understand the mechanisms that drive root-soil coupling to investigate midday depression of Rs

**Research Questions:** 

1. What is causing/driving this midday depression in Rs?
2. How are Rs and Js coupled in time and space?

## Preliminary Figures and Takeaway:

```{r functions, echo = FALSE, message = FALSE}
# Load functions
library(readr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(lubridate)
library(viridis)
library(wesanderson)
library(kableExtra)

# find matches
source(file = "find_day.R")

# count observations
log_obs <- function(d, step_name) {
  d %>% 
    ungroup() %>% 
    group_by(Tree) %>% 
    summarise(n = n()) %>% 
    mutate(step = step_name) %>% 
    bind_rows(obs_count_data) ->> obs_count_data
}

# computer rs-js correlation
cor_hour <- list()
hourly_cor <- function(dataset) {
  for(i in 1:24) {
    if (i %in% dataset$Hour) {
      dataset %>% 
        mutate(js_lag = lead(dataset$js, n = i)) -> lagged
      
    cor<- cor(lagged$rs, lagged$js_lag)
    }
    else {cor <- NA}
    s
    cor_hour[[i]] <<- cor
  }
}

```

```{r load-data, echo = FALSE, message = FALSE, warning = FALSE}
# Load in Rs, K, weather, and inventory data
inventory <- read_csv("../../PREMIS-stormsurge/inventory/ss-inventory.csv")
ports_lt <- read_csv("../../PREMIS-ghg/design/LT_portcodes.csv")
species_codes <- read_csv("../../PREMIS-ghg/inventory_data/species_codes.csv")

read_csv("../SERC/baseliner_data/control_Kest_yr.csv", 
         col_names = c("Year", "DOY","Time","VPD", "PAR", "C1", "C2", "C3", "C4", "C5", "C6", "C7", "C8")) %>% 
  mutate(Date = as_date(DOY - 1, origin = "2018-01-01")) %>% 
  separate(Date, c("Y", "Month", "Day"), sep = "-") %>% 
  separate(Time, c("Hour", "Min"), sep = -2) -> control_hm
  
control_hm$Hour[control_hm$Hour == ""] <- 0

control_hm %>% 
  mutate(Timestamp = mdy_hm(paste0(Month, "-", Day, "-", Year, " ", Hour, ":", Min))) %>%
  select(-Y, -Year, - Day, - Month) %>% 
  gather("Tree", "K", C1:C8) %>% 
  left_join(inventory, by = c("Tree" = "Sapflux")) %>% 
  select(Timestamp, VPD, PAR, K, Tree, Species_code, Plot) -> control_long

read_csv("../SERC/con_licor_data_20191120.csv") %>%
  left_join(ports_lt, by = "Port") %>% 
  left_join(inventory, by = c("Tree" = "Sapflux"))-> rs_long

# Load weather data
read_csv("../SERC/met_data/SECPRE_30min.csv") %>% 
  mutate(Timestamp = ymd_hms(endDateTime)) %>% 
  rename(Precip = secPrecipBulk) %>% 
  select(Timestamp, Precip) -> precip

read_csv("../SERC/met_data/RH_30min.csv") %>% 
  filter(horizontalPosition == "000", verticalPosition == "060") %>% 
  mutate(Timestamp = ymd_hms(endDateTime)) %>% 
  rename(RH = RHMean, Tair = tempRHMean) %>% 
  select(Timestamp, RH, Tair) -> temprh

read_csv("../SERC/met_data/PARPAR_30min.csv") %>% 
  mutate(Timestamp = ymd_hms(endDateTime), DOY = yday(Timestamp)) %>% 
  rename(PAR = PARMean) %>% 
  filter(verticalPosition == "060") %>% 
  select(Timestamp, DOY, PAR) %>%
  left_join(precip, by = "Timestamp") %>% 
  left_join(temprh, by = "Timestamp") %>% 
  mutate(Timestamp = round_date(Timestamp, unit = "hour")) %>% 
  group_by(Timestamp) %>% 
  summarise(DOY = mean(DOY), PAR = mean(PAR), 
            Precip = mean(Precip), RH = mean(RH), Tair = mean(Tair)) -> wx_dat

```

```{r data-cleaning, echo = FALSE, message = FALSE}
# Next, we need to filter for the Js trees that also have Rs measurements
rs_trees <- unique(ports_lt$Tree)
sunrise <- 6
sunset <- 19

control_long %>% 
  #Then, we need to transform K to Js (sapflux density) through a conversion
  mutate(Js = 119* 10^(-6) * K^(1.231)) %>% 
  filter(Tree %in% rs_trees) %>% 
  # Then, we need to round the timestamp to the nearest hour and take hourly averages
  mutate(Timestamp = round_date(Timestamp, unit = "hour")) %>% 
  # Now that all data are on a common timeframe, we can take the hourly mean of each dataset
  group_by(Timestamp, Tree, Species_code) %>% 
  summarise(Js_avg = mean(Js, na.rm = TRUE), VPD_avg = mean(VPD, na.rm = TRUE)) -> control_filter

rs_long %>%
  mutate(Timestamp = round_date(Timestamp, unit = "hour")) %>%
  group_by(Timestamp, Tree, Species_code) %>%
  summarise(rs_avg = mean(Flux), T5 = mean(T5, na.rm = TRUE), SM = mean(SMoist, na.rm = TRUE)) %>% 
  # need to replace bad T5 and SM data
  filter(rs_avg > 0, rs_avg < 25, SM > 0, SM < 1, T5 < 50) %>%
  ungroup() -> rs_filter

rs_long %>%
  filter(Flux > 0, Flux < 25, SMoist > 0) %>%
  mutate(Timestamp = round_date(Timestamp, unit = "hour")) %>%
  group_by(Timestamp, Tree, Species_code) %>%
  summarise(rs_avg = mean(Flux), T5 = mean(T5), SM = mean(SMoist)) %>% 
  ungroup() -> rs_filter

control_filter %>% 
  left_join(rs_filter) %>% 
  na.omit() %>% 
  left_join(wx_dat, by = "Timestamp") %>% 
  mutate(DOY = yday(Timestamp)) -> combined

combined %>% 
  mutate(Hour = hour(Timestamp)) %>% 
  group_by(Hour, Species_code) %>% 
  summarise(rs_havg = mean(rs_avg, na.rm = TRUE), Js_havg = mean(Js_avg, na.rm = TRUE), 
            DOY = mean(DOY, na.rm = TRUE), PAR = mean(PAR, na.rm = TRUE), 
            Precip = mean(Precip, na.rm = TRUE), VPD = mean(VPD_avg, na.rm = TRUE),
            RH = mean(RH, na.rm = TRUE), Tair = mean(Tair, na.rm = TRUE),
            SM = mean(SM, na.rm = TRUE), Tsoil = mean(T5, na.rm = TRUE)) %>% 
  mutate(Daytime = if_else(Hour > sunrise & Hour < sunset, TRUE, FALSE)) %>% 
  left_join(species_codes) -> hourly
#add SM and temp
gather(hourly, key = "Type", value = "Value", rs_havg:Js_havg) -> hourly_long

combined %>% 
  mutate(Date = date(Timestamp)) %>% 
  group_by(Date) %>% 
  summarise(rs_daily = mean(rs_avg, na.rm = TRUE), Js_daily = mean(Js_avg, na.rm = TRUE), 
            DOY = mean(DOY, na.rm = TRUE), PAR = mean(PAR, na.rm = TRUE), 
            Precip = mean(Precip, na.rm = TRUE), VPD = mean(VPD_avg, na.rm = TRUE),
            RH = mean(RH, na.rm = TRUE), Tair = mean(Tair, na.rm = TRUE), 
            SM = mean(SM, na.rm = TRUE), T5 = mean(T5, na.rm = TRUE)) -> daily

```

```{r check-count}
# Check Rs counts
obs_count_data <- tibble()
log_obs(rs_long, "1")
log_obs(rs_filter, "2")
log_obs(combined, "3")

ggplot(obs_count_data, aes(x = step, y = n, colour = Tree, group = Tree)) + 
  geom_line() +
  theme_minimal() -> rs_counts

# Check Js counts
tree_names <- c("C3", "C6", "C7", "C8")

obs_count_data <- tibble()
log_obs(control_long, "1")
log_obs(control_filter, "2")
log_obs(combined, "3")

ggplot(filter(obs_count_data, Tree %in% tree_names), aes(x = step, y = n, color = Tree, group = Tree)) + 
  geom_line() +
  theme_minimal() -> js_counts

```

```{r hourly, echo = FALSE, message = FALSE}
rs_min <- 7
rs_max <- 11

hourly_long[which(hourly_long$Type == "Js_havg"), ] -> x

hourly_long %>% 
  ungroup %>% 
  filter(Type == "Js_havg") %>% 
  select(-Value) %>% 
  mutate(Value  = (rs_max - rs_min) * ((x$Value - min(x$Value))/(max(x$Value) - min(x$Value))) + rs_min) -> hourly_check

hourly_long %>% 
  filter(Type == "rs_havg") %>% 
  bind_rows(hourly_check) -> hourly_norm

ggplot(filter(hourly_norm), aes(x = Hour, y = Value, color = Type, group = Type)) +
  geom_line() +
  geom_point(size = 1) +
  scale_color_viridis(discrete = TRUE, 
                      option = "D", 
                      begin =0.7, 
                      end = 0.4,
                      labels = c("Js", "Rs")) +
  labs(x = "Hour of Day", y = "Value") +
  facet_wrap(~Species) + 
  theme_minimal() +
  theme(strip.text.x = element_text(face = "bold.italic", size = 12)) 
  
```


```{r rs-js plot, echo = FALSE, message = FALSE}
ggplot(hourly, aes(x = Js_havg, rs_havg)) +
  geom_point(aes(color = Daytime)) +
  geom_smooth(aes(group = Daytime, color = Daytime, fill = Daytime), method = "lm") +
  scale_color_viridis(discrete = TRUE,
                      name = "Time of Day",
                      labels = c("Nighttime", "Daytime")) +
  scale_fill_viridis(discrete = TRUE,
                     name = "Time of Day",
                     labels = c("Nighttime", "Daytime")) +
  labs(x = "Js (m/s)", y = "Rs (umol/m/s)") +
  theme_minimal()

```


```{r Q10, echo = FALSE, message = FALSE}
combined %>% 
  mutate(Daytime = if_else(hour(Timestamp) > sunrise & hour(Timestamp) < sunset, TRUE, FALSE)) -> data

## Daytime Q10
daytime <- filter(data, Daytime == TRUE)
model_d <- lm(log(rs_avg) ~ T5, data = daytime)
daytime$prediction <- exp(predict(model_d))
# ggplot(daytime, aes(x = T5, y = rs_avg)) + 
#   geom_point() +
#   geom_line(data = daytime, aes(y = prediction), linetype = 2)
# cat("Model Q10 =", exp(10 ^ model_d$coefficients[2]))

## Nighttime Q10
nighttime <- filter(data, Daytime == FALSE)
model_n <- lm(log(rs_avg) ~ T5, data = nighttime)
nighttime$prediction <- exp(predict(model_n))
# ggplot(nighttime, aes(x = T5, y = rs_avg)) + 
#   geom_point() + 
#   geom_line(data = nighttime, aes(y = prediction), linetype = 2)
# cat("Model Q10 =", exp(10 ^ model_n$coefficients[2]))

## Plot
ggplot(data, aes(x = T5, y = rs_avg, color = Daytime)) + 
  geom_point() +
  scale_color_viridis(discrete = TRUE,
                      name = "Time of Day",
                      labels = c("Nighttime", "Daytime")) +
  annotate("text", x = 10, y = 21.5, 
           label = paste("Q10 =", round(exp(10 ^ model_d$coefficients[2]), digits = 3)), 
           color = "#FDE725FF") +
  annotate("text", x = 10, y = 20, 
          label = paste("Q10=", round(exp(10 ^ model_n$coefficients[2]), digits = 3)), 
          color = "#440154FF") +
  theme_minimal()

```

## Analysis Progress
- Rs, Js, and climate variables parsed to same timescale
- Data separated into **sunny days** (top 1/3 PAR) and **cloudy days** (bottom 1/3 PAR)

**Goal:** To compare Rs:Js correlation of sunny vs. cloudy days. We essentially are tested the important of PAR on the relationship.

```{r sunny-cloudy, echo = FALSE, message = FALSE, warning = FALSE}
daily %>% mutate(group = ntile(PAR, 3)) -> PAR_groups

pal <- (wes_palette(name = "Zissou1", 3, type = "continuous"))

ggplot(PAR_groups, aes(x = group, y = log(PAR), color = as.factor(group))) + 
  geom_jitter() + 
  ggtitle("PAR") + 
  scale_colour_manual(values = pal, name = "Tercile") + 
  theme_minimal()

sunny <- filter(PAR_groups, group == "3") %>% select(DOY)
cloudy <- filter(PAR_groups, group == "1") %>% select(DOY)

combined %>% 
  ungroup() %>% 
  select(DOY, VPD_avg, T5, SM, Precip, RH, Tair) %>% 
  group_by(DOY) %>% 
  summarise(VPD = mean(VPD_avg), T5 = mean(T5), SM = mean(SM),
            Precip = mean(Precip), RH = mean(RH, na.rm = T), Tair = mean(Tair, na.rm = T)) -> climate_data

constraints <- c("VPD" = 1, "T5" = 5, "SM" = 1, "Precip" = 4, "RH" = 30, "Tair" = 15)

matches <- list()

for(i in 1:nrow(daily)) {
  matches[[i]] <- tibble(DOY = daily$DOY[i], Similar_Day = similar_days(daily$DOY[i], climate_data, lookahead = 7, constraints))
}

bind_rows(matches) -> matches_df

matches_df %>% 
  filter(DOY %in% sunny$DOY) %>% 
  filter(Similar_Day %in% cloudy$DOY) %>% 
  rename(Sunny_DOY = DOY, Cloudy_DOY = Similar_Day) -> matched_DOY

left_join(matched_DOY, combined, by = c("Cloudy_DOY" = "DOY")) %>%
  mutate(Coverage = "Cloudy") %>% 
  rename(DOY = Cloudy_DOY, Match_DOY = Sunny_DOY) -> cloudy_complete

left_join(matched_DOY, combined, by = c("Sunny_DOY" = "DOY")) %>% 
  mutate(Coverage = "Sunny") %>% 
  rename(DOY = Sunny_DOY, Match_DOY = Cloudy_DOY) -> sunny_complete

bind_rows(cloudy_complete, sunny_complete) -> matches_data

```

Number of Js obs: `r nrow(combined)`
Number of Rs obs: `r nrow(combined)`

```{r q10-sunny-cloudy}

## Sunny Q10
sunny <- filter(matches_data, Coverage == "Sunny")
model_s <- lm(log(rs_avg) ~ T5, data = sunny)
sunny$prediction <- exp(predict(model_s))
# ggplot(daytime, aes(x = T5, y = rs_avg)) + 
#   geom_point() +
#   geom_line(data = daytime, aes(y = prediction), linetype = 2)
# cat("Model Q10 =", exp(10 ^ model_d$coefficients[2]))

## Cloudy Q10
cloudy <- filter(matches_data, Coverage == "Cloudy")
model_c <- lm(log(rs_avg) ~ T5, data = cloudy)
cloudy$prediction <- exp(predict(model_c))
# ggplot(nighttime, aes(x = T5, y = rs_avg)) + 
#   geom_point() + 
#   geom_line(data = nighttime, aes(y = prediction), linetype = 2)
# cat("Model Q10 =", exp(10 ^ model_n$coefficients[2]))

## Plot
ggplot(matches_data, aes(x = T5, y = rs_avg, color = Coverage)) + 
  geom_point() +
  scale_color_viridis(discrete = TRUE) +
  annotate("text", x = 10, y = 21.5, 
           label = paste("Q10 =", round(exp(10 ^ model_s$coefficients[2]), digits = 3)), 
           color = "#FDE725FF") +
  annotate("text", x = 10, y = 20, 
          label = paste("Q10=", round(exp(10 ^ model_c$coefficients[2]), digits = 3)), 
          color = "#440154FF") +
  theme_minimal()

```

## Lag Analysis

```{r lag-analysis}

matches_data %>% 
  filter(Coverage == "Sunny") %>% 
  mutate(Hour = hour(Timestamp)) %>% 
  group_by(Tree, Hour) %>% 
  summarise(Rs = mean(rs_avg), Js = mean(Js_avg)) -> dataframe_sunny

matches_data %>% 
  filter(Coverage == "Cloudy") %>% 
  mutate(Hour = hour(Timestamp)) %>% 
  group_by(Hour) %>% 
  summarise(Rs = mean(rs_avg), Js = mean(Js_avg)) -> dataframe_cloudy

# lags <- list()
# for(i in 0:24) {
#   dataframe_cloudy %>% 
#     mutate(Lag = lead(Hour, n = i)) -> x
#   
# }

  


```

Number of Js obs: `r nrow(combined)`

